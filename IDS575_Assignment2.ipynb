{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsany94/symptom-chatbot/blob/main/IDS575_Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAG Pipeline"
      ],
      "metadata": {
        "id": "j6cKVn9sc5Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai langchain-openai faiss-cpu rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YkMiCvWec7GW",
        "outputId": "4f73060e-dcf1-427b-95f3-9ee4356dc6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.68.2)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.45)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai) (0.3.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-openai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import faiss\n",
        "import openai\n",
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from google.colab import auth\n",
        "from google.colab import userdata\n",
        "from googleapiclient.discovery import build\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "c8QUKqkWeAcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate and connect to Google Drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define path to the folder containing text files\n",
        "TEXT_FOLDER = \"/content/drive/My Drive/Sample_Data/\"\n",
        "\n",
        "# Verify if the folder exists\n",
        "if not os.path.exists(TEXT_FOLDER):\n",
        "    print(\"⚠️ Folder not found! Check your Google Drive path.\")\n",
        "else:\n",
        "    print(\"✅ Google Drive mounted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CstrP46ueKKo",
        "outputId": "51d02556-49f9-4ac4-a35b-87f6999f8b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- STEP 2: Set OpenAI API Key ----\n",
        "api_key = userdata.get('OPENAI_KEY')\n",
        "\n",
        "if api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "    print(\"✅ OpenAI API key is set.\")\n",
        "else:\n",
        "    print(\"⚠️ OpenAI API key not found! Please set it manually.\")\n",
        "\n",
        "# Set up OpenAI Client\n",
        "client = openai.Client(api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw7diFcDf3eS",
        "outputId": "20e692e3-87fb-4acc-a0f8-d2688f41dc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ OpenAI API key is set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- STEP 3: Load and Process Text Files ----\n",
        "def load_text_files(folder_path):\n",
        "    documents = []\n",
        "    filenames = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "                documents.append(text)\n",
        "                filenames.append(filename)\n",
        "\n",
        "    return documents, filenames\n",
        "\n",
        "# ---- STEP 4: Split text into smaller chunks ----\n",
        "def split_text_into_chunks(texts, chunk_size=1200, overlap=50):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
        "    return [chunk for text in texts for chunk in splitter.split_text(text)]\n",
        "\n",
        "# ---- STEP 5: Create and Store Embeddings in FAISS ----\n",
        "def create_faiss_index(chunks):\n",
        "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    embeddings = np.array([embedding_model.embed_query(chunk) for chunk in chunks], dtype=np.float32)\n",
        "\n",
        "    d = embeddings.shape[1]  # Embedding dimension\n",
        "    M = 32  # Number of connections per node in HNSW graph\n",
        "\n",
        "    index = faiss.IndexHNSWFlat(d, M)  # Hierarchical Navigable Small World (HNSW)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    return index, chunks\n",
        "\n",
        "# ---- STEP 6: Create FAISS Index using Batch Processing ----\n",
        "def create_faiss_index_batch_model(chunks, batch_size=10):\n",
        "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    embeddings = []\n",
        "\n",
        "    # Batch processing for embeddings\n",
        "    for i in range(0, len(chunks), batch_size):\n",
        "        batch = chunks[i: i + batch_size]\n",
        "        batch_embeddings = embedding_model.embed_documents(batch)  # Batch call\n",
        "        embeddings.extend(batch_embeddings)\n",
        "\n",
        "    embeddings = np.array(embeddings, dtype=np.float32)\n",
        "\n",
        "    d = embeddings.shape[1]  # Embedding dimension\n",
        "    index = faiss.IndexFlatL2(d)\n",
        "    index.add(embeddings)\n",
        "\n",
        "    return index, chunks\n",
        "\n",
        "# ---- STEP 7: Setup BM25 Re-Ranking ----\n",
        "def setup_bm25(chunks):\n",
        "    tokenized_corpus = [chunk.split() for chunk in chunks]\n",
        "    return BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# ---- STEP 8: Retrieve & Re-Rank Chunks ----\n",
        "def retrieve_and_rerank(query, index, chunks, bm25_model, top_k=10, rerank_top_n=5):\n",
        "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    query_embedding = np.array([embedding_model.embed_query(query)], dtype=np.float32)\n",
        "\n",
        "    # Retrieve top-K nearest chunks from FAISS\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
        "\n",
        "    # BM25 Re-Ranking\n",
        "    tokenized_query = query.split()\n",
        "    bm25_scores = bm25_model.get_scores(tokenized_query)\n",
        "\n",
        "    # Sort and return top rerank_top_n chunks\n",
        "    ranked_chunks = sorted(zip(retrieved_chunks, bm25_scores), key=lambda x: x[1], reverse=True)[:rerank_top_n]\n",
        "\n",
        "    return [chunk for chunk, score in ranked_chunks]\n",
        "\n",
        "# ---- STEP 9: Generate Answer using OpenAI GPT-4 ----\n",
        "def generate_response(query, retrieved_chunks):\n",
        "    context = \"\\n\".join(retrieved_chunks)\n",
        "    prompt = f\"User Query: {query}\\n\\nRelevant Context:\\n{context}\\n\\nAnswer:\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Answer the query based on the provided context.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "8uKT0PTWgh-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- STEP 10: RUN THE FULL RAG PIPELINE ----\n",
        "print(\"\\n🔄 Loading text files...\")\n",
        "documents, filenames = load_text_files(TEXT_FOLDER)\n",
        "print(\"✅ Done loading!\")\n",
        "\n",
        "print(\"\\n🔄 Splitting text into chunks...\")\n",
        "chunks = split_text_into_chunks(documents)\n",
        "print(f\"✅ Done chunking! Total chunks: {len(chunks)}\")\n",
        "\n",
        "print(\"\\n🔄 Creating FAISS index...\")\n",
        "faiss_index, processed_chunks = create_faiss_index_batch_model(chunks, batch_size=10)\n",
        "print(\"✅ Done embedding and indexing!\")\n",
        "\n",
        "print(\"\\n🔄 Setting up BM25 re-ranking...\")\n",
        "bm25_model = setup_bm25(processed_chunks)\n",
        "print(\"✅ Done with BM25 re-ranking!\")\n",
        "\n",
        "# Example Query\n",
        "query = \"What are the key challenges in AI adoption?\"\n",
        "print(f\"\\n🔍 Query: {query}\")\n",
        "\n",
        "print(\"\\n🔄 Retrieving and re-ranking relevant chunks...\")\n",
        "retrieved_chunks = retrieve_and_rerank(query, faiss_index, processed_chunks, bm25_model)\n",
        "print(\"✅ Done with retrieval!\")\n",
        "\n",
        "print(\"\\n📝 Generating response using GPT-4...\")\n",
        "response = generate_response(query, retrieved_chunks)\n",
        "\n",
        "# ---- STEP 11: DISPLAY RESULTS ----\n",
        "print(\"\\n📌 Retrieved Context:\")\n",
        "for chunk in retrieved_chunks:\n",
        "    print(f\"- {chunk}\\n\")\n",
        "\n",
        "print(\"\\n🤖 AI-Generated Response:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73S07NXWg2bq",
        "outputId": "d0d771d9-f2df-4f81-c6d2-7bf25da0f274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Loading text files...\n",
            "✅ Done loading!\n",
            "\n",
            "🔄 Splitting text into chunks...\n",
            "✅ Done chunking! Total chunks: 185\n",
            "\n",
            "🔄 Creating FAISS index...\n",
            "✅ Done embedding and indexing!\n",
            "\n",
            "🔄 Setting up BM25 re-ranking...\n",
            "✅ Done with BM25 re-ranking!\n",
            "\n",
            "🔍 Query: What are the key challenges in AI adoption?\n",
            "\n",
            "🔄 Retrieving and re-ranking relevant chunks...\n",
            "✅ Done with retrieval!\n",
            "\n",
            "📝 Generating response using GPT-4...\n",
            "\n",
            "📌 Retrieved Context:\n",
            "- Personalization At Scale\n",
            "Companies are leveraging AI to deliver highly personalized experiences. Duolingo, for instance, uses generative AI to create dynamic language exercises tailored to individual learning patterns. This level of personalization extends across industries, from e-commerce product recommendations to financial service offerings.\n",
            "\n",
            "The Challenge Landscape\n",
            "The path to AI implementation is filled with intriguing paradoxes:\n",
            "\n",
            "The Data Dilemma\n",
            "One of the primary challenges enterprises face is maintaining fresh, accurate data in their AI systems. It's like trying to hit a moving target while standing on shifting sand. Organizations must carefully manage:\n",
            "\n",
            "• Continuous data ingestion and synchronization.\n",
            "\n",
            "• Detection of data drift and model performance degradation.\n",
            "\n",
            "• Version dependencies between data sources and models.\n",
            "\n",
            "• Efficient updating of models without complete retraining.\n",
            "\n",
            "The Security Puzzle\n",
            "Security remains a paramount concern:\n",
            "\n",
            "• Protection of sensitive enterprise data.\n",
            "\n",
            "• Compliance with access control requirements.\n",
            "\n",
            "• Prevention of unauthorized data exposure.\n",
            "\n",
            "• Implementation of effective guardrails against misuse.\n",
            "\n",
            "- The operational headwinds that slow execution\n",
            "Business adoption of AI faces several operational headwinds. Our interviews and research surfaced five that are most challenging: aligning leadership, addressing cost uncertainty, workforce planning, managing supply chain dependencies, and meeting the demand for explainability.\n",
            "\n",
            "- 9 Common AI Adoption Challenges That Threaten AI Success (And How to Solve Them)\n",
            "1. Lack of a Strategic Vision for AI Opportunities\n",
            "The Problem: Artificial intelligence is only as effective as the strategy behind it, and this factor alone has tripped many organizations up. With all the hype surrounding the technology, it can be easy to jump on the wagon without doing sufficient research on how to best infuse it into one’s organization.\n",
            "\n",
            "The Fix: To avoid letting your AI initiative become disjointed and fail to deliver expected results, you need to establish a strategic vision for embracing AI opportunities. In practice, that means conducting a thorough analysis of your business processes to identify areas where AI can have the most significant impact. To determine these areas and their best use cases, engage a cross-functional team to map out a detailed AI roadmap that includes specific goals, timelines, and key performance indicators (KPIs) to track progress.\n",
            "\n",
            "- Overcoming common challenges to AI adoption requires a holistic approach that includes not just AI development teams but stakeholders from across technology, finance, security and legal departments. However, considering how quickly the technology is moving, the best time for stragglers to get started is today.\n",
            "\n",
            "- The 5 biggest AI adoption challenges for 2025\n",
            "5 years ago, IBM’s Rob Thomas and Paul Zikopoulos built a framework for successful artificial intelligence (AI) adoption called the AI Ladder, a “unified, prescriptive approach to help [leaders] understand and accelerate the AI journey.” The framework became a book, which was teased with a hook that now seems rather quaint:\n",
            "\n",
            "“Everybody’s talking about AI. Why? Well, we believe AI presents a tremendous opportunity for businesses of every size across any industry.”\n",
            "\n",
            "Considering the AI landscape today, it’s funny to imagine a world where Rob and Paul felt the need to persuade readers that AI was going to be a big deal. Also notable are the “rungs” of the ladder: modernize, collect, organize, analyze and infuse.\n",
            "\n",
            "Back in 2020, there were numerous organizations that hadn’t even begun to lift their foot onto that first rung. Just 5 short years later, you don’t need a McKinsey report to tell you that AI is the future.\n",
            "\n",
            "Virtually every organization can embrace AI to one degree or another. New technology advancements have made it easier to accomplish AI integrations that produce immediate return on investment (ROI).\n",
            "\n",
            "\n",
            "🤖 AI-Generated Response:\n",
            "The key challenges in AI adoption include maintaining fresh and accurate data in AI systems, security concerns such as data protection and compliance, operational issues such as aligning leadership, cost uncertainty, workforce planning, supply chain dependencies, and meeting the demand for explainability. Other significant challenges are a lack of strategic vision for AI opportunities and the need for a holistic approach to AI adoption that includes stakeholders from various departments. Finally, with the speed at which AI technology is advancing, organizations also face challenges in keeping up to date.\n"
          ]
        }
      ]
    }
  ]
}